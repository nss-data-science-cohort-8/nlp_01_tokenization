{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a993410",
   "metadata": {},
   "source": [
    "## Tokenization Practice and Simple Document Similarity\n",
    "\n",
    "For this notebook, you have been provided the top 50 most downloaded books from Project Gutenberg over the last 90 days as text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7bfc0",
   "metadata": {},
   "source": [
    "Given a filepath, you can open the file and use the `read` method to extract the contents as a string.\n",
    "\n",
    "For example, if we want to import the full text of War and Peace, we can do that using the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'books/War and Peace by graf Leo Tolstoy.txt'\n",
    "\n",
    "with open(filepath, encoding = 'utf-8') as fi:\n",
    "    book = fi.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa5918c",
   "metadata": {},
   "source": [
    "You'll notice that there is some metadata at the top of the file and at the bottom of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "book[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "book[-18420:-18000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b5b54",
   "metadata": {},
   "source": [
    "Write some code that will remove this text at the bottom and top of the string.\n",
    "\n",
    "**Hint:** You might want to make use of the [`re.search`](https://docs.python.org/3/library/re.html#re.search) function from the `re` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44329b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815edb06",
   "metadata": {},
   "source": [
    "If we want to be able to scale up our analysis to multiple books, it would be nice to have a function to use repeatedly. Write a function called `import_book` which takes as an argument a filepath and returns the contents of that file as a string with the metadata at the top and bottom removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597bdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47559e",
   "metadata": {},
   "source": [
    "Now, let's utilize our function to import all of the books into a data structure of some kind.\n",
    "\n",
    "First, we need to be able to iterate through the list of filepaths. For this, we can use the `glob` function. This function takes as agument a pattern to match. Try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4648a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('books/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ae912",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = glob.glob('books/*.txt')[0]\n",
    "filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ad8b3",
   "metadata": {},
   "source": [
    "It would be nice to save the title of each book without the extra pieces around it. Write code that will remove the \"books/\" from the front of the filepath and the \".txt\" from the end. That is, we want to extract just the \"Little Women by Louisa May Alcott\" from the current filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c1bc8",
   "metadata": {},
   "source": [
    "Now, combine together the function you created and the code that you just wrote to iterate through the filepaths for the books and save the contents of each book into a dictionary whose keys are equal to the cleaned up titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ac780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886f8d8",
   "metadata": {},
   "source": [
    "Now let's write some code so that we can cluster our books. In order to cluster, we'll need to be able to compute a similarity or distance between books.\n",
    "\n",
    "A simple way to compute similarity of documents is the [Jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index) of the set of words that they conain. This metric computes the amount of overlap between two sets compared to their union. Two books which contain exactly the same words (but not necessarily in the same order or with the same frequency) will have a Jaccard similarity of 1 and two books which have no words in common will have a Jaccard similarity of 0.\n",
    "\n",
    "**Question:** What might be some of the downsides to using Jaccard similarity to compute the similarity of two books?\n",
    "\n",
    "In order to use this, we'll need to tokenize each book and store the results in a collection of some kind. Since we are interested in which words appear but not necessarily in what order or how frequently, we can make use of a [set](https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset). A set is similar to a list, but the order of the contents does not matter and a set cannot contain duplicates.\n",
    "\n",
    "For practice, let's grab one of our books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca160e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = books['Little Women by Louisa May Alcott']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46afe2b",
   "metadata": {},
   "source": [
    "Write some code which tokenizes Little Women and stores the tokens it contains in a set. It is up to you to decide exactly how you want to tokenize or what you want to count as a token.\n",
    "\n",
    "Once you are happy with your tokenization method, convert it into a function named `tokenize_book` which takes in a string and returns a set of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa23531",
   "metadata": {},
   "source": [
    "Now, write a function `jaccard` which takes in two sets of tokens and returns the Jaccard similarities between them. **Hint:** Python sets have `intersection` and `union` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f40caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fb749",
   "metadata": {},
   "source": [
    "Is Little Women more similar (using Jaccard Similarity) to Heart of Darkness or Anthem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c739125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86b209",
   "metadata": {},
   "source": [
    "Let's create another dictionary called `book_tokens` that contains the title of each book as a key and the tokenized version of the book as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301afd4c",
   "metadata": {},
   "source": [
    "Using this, let's create a distance matrix for our books using the jaccard function above. **Note:** You created a function for jaccard _similarity_. This can be converted to a **distance** by subtracting the similarity score from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.zeros(shape = (len(book_tokens), len(book_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28caa134",
   "metadata": {},
   "source": [
    "Now, fill in the distance matrix so that in the i,j spot you have one minus the jaccard similarity of the ith and jth books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75384655",
   "metadata": {},
   "source": [
    "Once we have our distance matrix, we can compute a **dendogram**. \n",
    "\n",
    "A dendogram is a way to visualize a hierarchical clustering of a dataset. You can read more about it [here](https://www.statisticshowto.com/hierarchical-clustering/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f722f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergings = linkage(squareform(dists), method='complete')\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "dendrogram(mergings,\n",
    "           labels = list(book_tokens.keys()),\n",
    "           leaf_rotation = 90,\n",
    "           leaf_font_size = 6);\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/dendogram_complete_jaccard.png', transparent=False, facecolor='white', dpi = 150);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbd4fc",
   "metadata": {},
   "source": [
    "**Bonus Material** Jaccard Similarity does not account for the frequency that each word is used, only whether or not it is used.\n",
    "\n",
    "We might be better off using the **cosine similarity** as a way to measure the similarity of two books.\n",
    "\n",
    "Create a dataframe named `books_df` where each row corresponds to a book and each column corresponds to a word. It should count the number of times the word appears in that book (including zero). Use the book title as the index of this dataframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
